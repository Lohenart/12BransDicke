{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\Lambda$CDM: $(\\Omega_{M}, w_0, H_0, \\Omega_{b}h^2)$ Flat Universe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 Points for BAO. R (shift parameter) for CMB. Panstarrs for SNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arturo/anaconda/lib/python2.7/site-packages/IPython/nbformat.py:13: ShimWarning: The `IPython.nbformat` package has been deprecated. You should import from nbformat instead.\n",
      "  \"You should import from nbformat instead.\", ShimWarning)\n",
      "/Users/arturo/anaconda/lib/python2.7/site-packages/nbformat/current.py:19: UserWarning: nbformat.current is deprecated.\n",
      "\n",
      "- use nbformat for read/write/validate public API\n",
      "- use nbformat.vX directly to composing notebooks of a particular version\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import emcee # to MCMC\n",
    "import triangle # to plot MCMC results\n",
    "import numpy as np\n",
    "from scipy.integrate import quad as intquad # To integrate\n",
    "\n",
    "from scipy.interpolate import interp1d # To interpolate the integral in the luminosity distance\n",
    "\n",
    "import matplotlib.pyplot as plt # To plot\n",
    "from matplotlib.ticker import MaxNLocator, NullFormatter  # \n",
    "\n",
    "# ---- To call other iPython codes/notebooks ----\n",
    "import io\n",
    "import nbformat\n",
    "from  IPython.nbformat import current # deprecated\n",
    "\n",
    "# -----------------\n",
    "\n",
    "# import scipy.optimize as op\n",
    "#import math\n",
    "# from math import log10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directory to save the data and figures.\n",
    "\n",
    "DirectoryToSaveThePlots = '/Users/arturo/Dropbox/Research/Articulos/12-BransDick-Norman/Compute/Plots/' \n",
    "# DirectoryToSaveThePlots = '/Users/arturo/Dropbox/Research/Articulos/0-LCDM-model/emcee/Om-w0-Ho-OmBh2-MAIN/Runs/BAO/8Points/' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General fixed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = 299792.458  # Speed of light\n",
    "\n",
    "HoFix = 70.\n",
    "\n",
    "T_CMB = 2.728 # Temperature of the CMB today, in units of Kelvins\n",
    "OmGammah2 = 2.469*10.**(-5.) # Present amount of photons * h^2. The present total radiation is OmRad = OmGamma + OmNeutrinos.\n",
    "OmRFix =0.000085 # Radiation component today\n",
    "OmBh2Fix = 0.02205 # Planck+WMAP constraint\n",
    "\n",
    "# Range of redshift to interpolate the luminosity distance function\n",
    "zminInterp= 0.\n",
    "zmaxInterp= 1.8\n",
    "nbinszInterp = 31\n",
    "typeInterp = 'quadratic' # kind of interpolation: 'cubic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling functions from another ipython code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining a function that allows me to call and run other ipython codes.\n",
    "\n",
    "def execute_notebook(nbfile):\n",
    "    \n",
    "    with io.open(nbfile) as f:\n",
    "        nb = current.read(f, 'json')\n",
    "        \n",
    "    ip = get_ipython()\n",
    "    \n",
    "    for cell in nb.worksheets[0].cells:\n",
    "        if cell.cell_type != 'code':\n",
    "            continue\n",
    "        ip.run_cell(cell.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the notebook containing all the cosmological functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "execute_notebook(\"BransDickeModelDefinition.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code containing the BAO and CMB definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# execute_notebook(\"MAIN-BAO-CMB-Probes.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$d_L = (1+z)^2 D_A$\n",
    "\n",
    "$d_L$ = luminosity distance\n",
    "\n",
    "$D_A$ = Angular diameter distance\n",
    "\n",
    "$D_A = \\frac{c}{H_0} \\frac{{\\rm Sinx} \\left[ H_0 \\sqrt{|\\Omega_K|} \\int^z_0 (dz/H(z)) \\right] }{(1+z)\\sqrt{|\\Omega_K}|}$\n",
    "\n",
    "with Sinx = $\\sin(x)$, $x$, $\\sinh (x)$ for $\\Omega_k <0, \\Omega_k=0, \\Omega_k>0$ respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Actual luminosity distance:\n",
    "# 571.54638336\n",
    "# Interpolated luminosity distance:\n",
    "# 571.546400983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/arturo/Dropbox/Research/Articulos/12-BransDick-Norman/Compute'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_SNe_np = np.genfromtxt('Union2_1-SCP-2012.txt', usecols=0)\n",
    "mu_SNe_np = np.genfromtxt('Union2_1-SCP-2012.txt', usecols=1)\n",
    "muError_SNe_np = np.genfromtxt('Union2_1-SCP-2012.txt', usecols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ln({\\rm Likelihood}_{\\rm SNe}) = -0.5 \\chi^2_{SNe}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def lnLikelihood_SNe(theta, z, mu, muError):\n",
    "    \"Natural logarithm (ln) of the Likelihood function = -0.5 * Chi2 \"\n",
    "    w, OmL, OmNu = theta\n",
    "      \n",
    "    chi2SNeInt = 0.\n",
    "    Ho = HoFix\n",
    "    \n",
    "    for i in range(len(z)):\n",
    "        # Chi2 definition\n",
    "        chi2SNeInt = (chi2SNeInt + ((5.*np.log10(LumDist_Simple(z[i], w, OmL, OmNu, Ho)) + 25.- \n",
    "                         mu[i])/muError[i])**2.)\n",
    "    \n",
    "    lnLikelihoodInt=0.\n",
    "    lnLikelihoodInt=-0.5*chi2SNeInt\n",
    "        \n",
    "    return lnLikelihoodInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4658.9477420278481"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1= 500., 0.7, 0.01\n",
    "lnLikelihood_SNe(theta1, z_SNe_np, mu_SNe_np, muError_SNe_np)\n",
    "\n",
    "# -4658.9477420278481"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ln({\\rm Likelihood}_{\\rm BAO}) \\propto -0.5\\chi^2_{BAO}$. 8 Points\n",
    "\n",
    "Using the 8 points shown in table VI of my paper about the dimensionless age of the  Universe.\n",
    "\n",
    "Approximation for $r_s$.\n",
    "\n",
    "See also table 6 of 2014-09-02-Rest-Kirshner-Etal-PANSTARRS-CosmologicalConstraintsFromSNeIaDuring1HalfYear-v2-N.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using just 8 points as in Panstarss et al 2014.\n",
    "'''\n",
    "def lnLikelihood_BAO(theta):\n",
    "    \"Chi^2_BAO\"\n",
    "    OmM, wde, Ho, OmBh2 = theta\n",
    "    \n",
    "    # Assumptions about some values:\n",
    "    OmR = OmRFix\n",
    "    \n",
    "    \n",
    "    chi2_BAOInt = (((DVFlat(0.106, OmM, wde, Ho, OmBh2, OmR)-457)/27)**2.+\n",
    "                   ((d_z_Approx(0.20, OmM, wde, Ho, OmBh2, OmR)-0.1905)/0.0061)**2. + \n",
    "                   ((d_z_Approx(0.35, OmM, wde, Ho, OmBh2, OmR)-0.1097)/0.0036)**2. + \n",
    "                   ((AA(0.44, OmM, wde, Ho, OmBh2, OmR)-0.474)/0.034)**2. + \n",
    "                   ((AA(0.60, OmM, wde, Ho, OmBh2, OmR)-0.442)/0.020)**2. + \n",
    "                   ((AA(0.73, OmM, wde, Ho, OmBh2, OmR)-0.424)/0.021)**2. + # I forget to include this point in the computations that I did for the paper with Bob. \n",
    "                   (((1./d_z_Approx(0.35, OmM, wde, Ho, OmBh2, OmR))-8.88)/0.17)**2. + \n",
    "                   (((1./d_z_Approx(0.57, OmM, wde, Ho, OmBh2, OmR))-13.67)/0.22)**2.\n",
    "                   )\n",
    "    return -0.5*chi2_BAOInt\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1=0.27, -1., 72, 0.0221\n",
    "lnLikelihood_BAO(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-8.9677368053993973\n",
    "-8.6859648654294759"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ln({\\rm Likelihood}_{\\rm BAO}) \\propto -0.5\\chi^2_{BAO}$. 1 Point: Percival (2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For 1-point of Percival:\n",
    "- Using $d_z(0.275) = 0.1390 \\pm 0.0037$ and with Gaussian prior on $\\Omega_M h^2 = 0.1326 \\pm 0.0063$\n",
    "\n",
    "- Following Percival et al. (2010). In this paper they assume a fixed value for $\\Omega_b h^2 = 0.0223$ argueing that WMAP has already constrained to tight this value (see pages 2155 and 2156).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def lnLikelihood_BAO(theta):\n",
    "    \"Chi^2_BAO\"\n",
    "    OmM, wde, Ho, OmBh2 = theta  \n",
    "    # Assumptions about some values:\n",
    "    OmR = OmRFix\n",
    "    OmBh2 = 0.0223\n",
    "    \n",
    "    chi2_BAOInt =  (((d_z_Approx(0.275, OmM, wde, Ho, OmBh2, OmR)-0.139)/0.0037)**2.+ \n",
    "                   ((OmM*(Ho/100.)**2. - 0.1326)/0.0063)**2.  # As in Percival (2010)\n",
    "                   ) \n",
    "    \n",
    "    return -0.5*chi2_BAOInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1=0.27, -1., 72, 0.0223\n",
    "lnLikelihood_BAO(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -0.90410732023428819\n",
    "-1.5880002907558326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ln({\\rm Likelihood}_{\\rm BAO}) \\propto -0.5\\chi^2_{BAO}$. 3 Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just 3 points as in Betoule et al 2014, z = 0.106, 0.35, 0.57."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using just 3 points as in Betoule et al 2014, z = 0.106, 0.35, 0.57.\n",
    "'''\n",
    "def lnLikelihood_BAO(theta):\n",
    "    \"Chi^2_BAO\"\n",
    "    OmM, Ho = theta\n",
    "    \n",
    "    # Assumptions about some values:\n",
    "    OmBh2 = OmBaryonh2\n",
    "    wde = -1.\n",
    "    \n",
    "    chi2_BAOInt = (4444.*(d_z_Approx(0.106, OmM, wde, Ho, OmBh2, OmRadiation)-0.336)**2.+\n",
    "                   215156.*(d_z_Approx(0.35, OmM, wde, Ho, OmBh2, OmRadiation)-0.1126)**2.+\n",
    "                   721487.*(d_z_Approx(0.57, OmM, wde, Ho, OmBh2, OmRadiation)-0.07315)**2.)\n",
    "    return -0.5*chi2_BAOInt\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1=0.27, 72\n",
    "lnLikelihood_BAO(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -7.3381747082998565"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ln({\\rm Likelihood}_{\\rm CMB}) \\propto -0.5\\chi^2_{CMB}$. $(\\omega_b, \\omega_c, 100\\theta_*)$\n",
    "### 3 distance priors like Betoule et al 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\omega_b \\equiv \\Omega_bh^2$, $\\omega_c \\equiv \\Omega_ch^2$ where $\\Omega_c = \\Omega_{\\text{cold dark matter}}$\n",
    "\n",
    "$\\theta(z) \\equiv r_s(z_*)/D_A(z)$\n",
    "\n",
    "The covariance matrix comes from equation (20) of Betoule et al 2014.\n",
    "\n",
    "16-CosmologicalParameters-Published-N.pdf (Planck):\n",
    "- Equation (10) and section 3.1\n",
    "- Table 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import array, linalg, dot # For invert a matrix, dot product, etc.\n",
    "\n",
    "CovMatrixCMB_Betoule = np.array([[0.79039, -4.0042, 0.80608],\n",
    "                                [-4.0042, 66.950, -6.9243],\n",
    "                                [0.80608, -6.9243, 3.9712]])*10**(-7.)\n",
    "\n",
    "# Computing the inverse of the matrix\n",
    "InvCovMatrixCMB_Betoule = linalg.inv(CovMatrixCMB_Betoule)\n",
    "print InvCovMatrixCMB_Betoule\n",
    "\n",
    "#-----------------------------\n",
    "\n",
    "# Vector of the difference between the theoretical and observed values for (wb,wc,100theta).\n",
    "def VectorCMBDiff(OmM, wde, Ho, OmBh2, OmR):\n",
    "    \"Vector of difference\"\n",
    "    VectorCMBDiffInt = np.array([OmBh2 - 0.022065, \n",
    "                          OmM*(Ho/100.)**2.-0.1199, \n",
    "                          100.*theta_MC(OmM, wde, Ho, OmBh2, OmR)-1.041])   \n",
    "    return VectorCMBDiffInt\n",
    "\n",
    "print VectorCMBDiff(0.27, -1.05, 70, 0.0221, 0.00008)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# array([[ 19852740.80848543,    940131.81114378,  -2390497.23282662],\n",
    "#       [   940131.81114378,    226747.26163745,    204533.79669354],\n",
    "#       [ -2390497.23282662,    204533.79669354,   3359988.25994207]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# array([  3.50000000e-05,   1.24000000e-02,   6.85663881e-03])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3 CMB priors from Planck + WMAP (following Betoule et al 2014)\n",
    "'''\n",
    "def lnLikelihood_CMB(theta):\n",
    "    \n",
    "    OmM, wde, Ho, OmBh2 = theta\n",
    "    \n",
    "    # Assumptions about some values:\n",
    "    OmR = OmRFix\n",
    "    \n",
    "    # Evaluating the function of the difference between the theoretical\n",
    "    # and the observed distance modulus.\n",
    "    DiffDistanceInt = VectorCMBDiff(OmM, wde, Ho, OmBh2, OmR)\n",
    "    \n",
    "    chi2CMB3PriorsInt=np.dot(DiffDistanceInt,np.dot(InvCovMatrixCMB_Betoule,DiffDistanceInt))\n",
    "    \n",
    "    return -0.5*chi2CMB3PriorsInt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1= 0.27, -1., 70, 0.0221\n",
    "lnLikelihood_CMB(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -36.677950217073615"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ln({\\rm Likelihood}_{\\rm CMB}) \\propto -0.5\\chi^2_{CMB}$.  $(l_a, R, \\omega_b)$ \n",
    "### 3 distance priors (Planck+WMAP+lensing), like Wang et al 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yun Wang and Shuang Wang, \"Distance priors from Planck and dark energy constraints from current data\", PHYSICAL REVIEW D 88, 043522 (2013).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import array, linalg, dot # For invert a matrix, dot product, etc.\n",
    "\n",
    "# The normalized covariance matrix for the distance priors derived \n",
    "# from Planck + WMAP + Lensing, from Wang et al (2013) \n",
    "NormalCovMatrix=np.array([[1, 0.5250, -0.4235],\n",
    "        [0.5250, 1, -0.6925],\n",
    "        [-0.4235, -0.6925, 1]])\n",
    "\n",
    "# The matrix of \"sigmas\"\n",
    "SigmaMatrix=np.array([[0.180*0.18, 0.180* 0.0094, 0.180*0.0003],\n",
    "                     [0.0094*0.18, 0.0094*0.0094, 0.0094*0.0003],\n",
    "                     [0.0003*0.18 ,0.0003*0.0094 ,0.0003*0.0003]])\n",
    "\n",
    "# Final covariance matrix\n",
    "CovMatrixCMB_Wang= NormalCovMatrix*SigmaMatrix\n",
    "# print CovMatrixCMB_Wang\n",
    "\n",
    "# Computing the inverse of the matrix\n",
    "InvCovMatrixCMB_Wang = linalg.inv(CovMatrixCMB_Wang)\n",
    "print InvCovMatrixCMB_Wang\n",
    "\n",
    "\n",
    "#-----------------------------\n",
    "\n",
    "# Vector of the difference between the theoretical and observed values for (wb,wc,100theta).\n",
    "def VectorCMBDiff_Wang(OmM, wde, Ho, OmBh2, OmR):\n",
    "    \"Vector of difference\"\n",
    "    VectorCMBDiffInt = np.array([l_a(OmM, wde, Ho, OmBh2, OmR) - 301.57,\n",
    "                                 R_CMB(OmM, wde, Ho, OmBh2, OmR)-1.7407,\n",
    "                                 OmBh2 - 0.02228])   \n",
    "    return VectorCMBDiffInt\n",
    "\n",
    "print VectorCMBDiff_Wang(0.27, -1.05, 70, 0.0221, 0.00008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [[  4.30179682e+01  -3.66771838e+02   2.97252812e+03]\n",
    "# [ -3.66771838e+02   2.48726571e+04   4.46498481e+05]\n",
    "# [  2.97252812e+03   4.46498481e+05   2.15547034e+07]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# array([ -1.75869593e+00,  -9.51296242e-03,  -1.80000000e-04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# 3 CMB priors from Planck + WMAP (following Wang et al 2013)\n",
    "\n",
    "def lnLikelihood_CMB(theta):\n",
    "    \n",
    "    OmM, wde, Ho, OmBh2 = theta\n",
    "    \n",
    "    # Assumptions about some values:\n",
    "    OmR = OmRFix\n",
    "    \n",
    "    # Evaluating the function of the difference between the theoretical\n",
    "    # and the observed distance modulus.\n",
    "    DiffDistanceInt = VectorCMBDiff_Wang(OmM, wde, Ho, OmBh2, OmR)\n",
    "    \n",
    "    chi2CMB3PriorsInt=np.dot(DiffDistanceInt,np.dot(InvCovMatrixCMB_Wang,DiffDistanceInt))\n",
    "    \n",
    "    return -0.5*chi2CMB3PriorsInt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1= 0.27, -1, 67, 0.0221\n",
    "lnLikelihood_CMB(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -46.248046330294969"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ln({\\rm Likelihood}_{\\rm CMB}) \\propto -0.5\\chi^2_{CMB}$.  $R$ only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yun Wang and Shuang Wang, \"Distance priors from Planck and dark energy constraints from current data\", PHYSICAL REVIEW D 88, 043522 (2013).\n",
    "\n",
    "NOTE: It missing to include the right covariance matrix if I decide to use the other distance priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def lnLikelihood_CMB(theta):\n",
    "    \n",
    "    OmM, wde, Ho, OmBh2  = theta\n",
    "    \n",
    "    # Assumptions about some values:\n",
    "    OmR = OmRFix\n",
    "\n",
    "    chi2_CMB = (((1.7407 - R_CMB(OmM, wde, Ho, OmBh2, OmR))/0.0094)**2.)\n",
    "    return -0.5*chi2_CMB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1= 0.27, -1, 72, 0.021\n",
    "lnLikelihood_CMB(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-1.8550956247239085\n",
    "-24.369314749773373\n",
    "-0.0037486681407561985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\ln({\\rm Posterior_{\\rm total}}) \\propto -0.5  \\chi^2_{total}$. With priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\chi^2_{total}$ = $\\chi^2_{SNe} + \\chi^2_{CMB} + \\chi^2_{BAO} + ({\\rm par}-{\\rm par}_{\\rm obs})^2/\\sigma^2_{\\rm par}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# WATCH OUT!: The priors have to be multiplied by \"-0.5\"!\n",
    "def lnPosteriorWithPriors(theta, z, mu, muError):\n",
    "    \"ln(Posterior) including Gaussian priors\"\n",
    "    OmM, wde, Ho, OmBh2 = theta\n",
    "    \n",
    "    # WATCH OUT!: The priors have to be multiplied by \"-0.5\"!\n",
    "    # At the end of the following expression, include any Gaussian prior\n",
    "    # on any parameters:\n",
    "    \n",
    "    lnPostWithPriorsInt =(lnLikelihood_SNe(theta, z, mu, muError) + \n",
    "                               lnLikelihood_CMB(theta) + \n",
    "                               lnLikelihood_BAO(theta) \n",
    "                               # + (-0.5)*((Ho-73.8)/2.4)**2.  \n",
    "                               )          \n",
    "    return lnPostWithPriorsInt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1= 0.27, -1, 70, 0.022\n",
    "lnPosteriorWithPriors(theta1, z_SNe_np, mu_SNe_np, muError_SNe_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-173.98778712395594\n",
    "-195.82859213726815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-198.92754151237639\n",
    "-198.89658221936472\n",
    "-224.01630580909358\n",
    "-177.24785580909355"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNe Only: $\\ln({\\rm Posterior_{\\rm total}}) \\propto -0.5  \\chi^2_{total}$. With priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WATCH OUT!: The priors have to be multiplied by \"-0.5\"!\n",
    "def lnPosteriorWithPriors(theta, z, mu, muError):\n",
    "    \"ln(Posterior) including Gaussian priors\"\n",
    "    w, OmL, OmNu = theta\n",
    "    \n",
    "    '''\n",
    "    if 0.<w<10000 and 0.<OmL<1 and 0.<OmNu<0.02:\n",
    "        lnPostWithPriorsInt = lnLikelihood_SNe(theta, z, mu, muError)\n",
    "        return lnPostWithPriorsInt\n",
    "    return -np.inf\n",
    "    '''\n",
    "     \n",
    "    lnPostWithPriorsInt = lnLikelihood_SNe(theta, z, mu, muError)\n",
    "    return lnPostWithPriorsInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4658.9477420278481"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1= 500., 0.7, 0.01\n",
    "lnPosteriorWithPriors(theta1, z_SNe_np, mu_SNe_np, muError_SNe_np)\n",
    "# -4658.9477420278481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-498.58004903496726"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1= 500., 0.7, -0.001\n",
    "lnPosteriorWithPriors(theta1, z_SNe_np, mu_SNe_np, muError_SNe_np)\n",
    "# -inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAO Only: $\\ln({\\rm Posterior_{\\rm total}}) \\propto -0.5  \\chi^2_{total}$. With priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For 1-point of Percival:\n",
    "- Using $d_z(0.275) = 0.1390 \\pm 0.0037$ and with Gaussian prior on $\\Omega_M h^2 = 0.1326 \\pm 0.0063$\n",
    "\n",
    "- Following Percival et al. (2010). In this paper they assume a fixed value for $\\Omega_b h^2 = 0.0223$ argueing that WMAP has already constrained to tight this value (see pages 2155 and 2156).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def lnPosteriorWithPriors_BAO(theta):\n",
    "    \"ln(Posterior) including Gaussian priors\"\n",
    "    OmM, wde, Ho, OmBh2 = theta\n",
    "    \n",
    "    # WATCH OUT!: The priors have to be multiplied by \"-0.5\"!\n",
    "    # At the end of the following expression, include any Gaussian prior\n",
    "    # on any parameters:\n",
    "    \n",
    "    lnPostWithPriorsInt = lnLikelihood_BAO(theta) \n",
    "  \n",
    "    return lnPostWithPriorsInt\n",
    "    ''' \n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1= 0.27, -1.05, 70, 0.0221\n",
    "lnPosteriorWithPriors_BAO(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-2.5471617321147706\n",
    "-0.17139981360338538 # For 1-point like in Percival assuming a Gaussian prior, with OmBh2 as free parameter\n",
    "-0.14595042592058885 # For 1-point like in Percival assuming a Gaussian prior, with OmBh2=0.0223"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMB Only: $\\ln({\\rm Posterior_{\\rm total}}) \\propto -0.5  \\chi^2_{total}$. With priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lnLikelihood_CMB(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def lnPosteriorWithPriors_CMB(theta):\n",
    "    \"ln(Posterior) including Gaussian priors\"\n",
    "    OmM, wde, Ho, OmBh2 = theta\n",
    "    \n",
    "    # WATCH OUT!: The priors have to be multiplied by \"-0.5\"!\n",
    "    # At the end of the following expression, include any Gaussian prior\n",
    "    # on any parameters:\n",
    "    \n",
    "    lnPostWithPriorsInt =lnLikelihood_CMB(theta)\n",
    "    \n",
    "    return lnPostWithPriorsInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1= 0.27, -1., 72, 0.0221\n",
    "lnPosteriorWithPriors_CMB(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -67.353289088107161 # 3 priors of wang\n",
    "# -63.323159143201366 # 3 CMB priors of Betoule\n",
    "# -1.8633312437581913 # R-CMB only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5+5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limits for each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lnPrior(theta):\n",
    "    \"Natural logarithm (ln) of the prior PDF\"\n",
    "    w, OmL, OmNu = theta\n",
    "    \n",
    "    if 0<w<10000 and 0.<OmL<1 and 0.0000000000001<OmNu<0.02:\n",
    "        return 0.0\n",
    "    return -np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ln(posterior PDF):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNe only or SNe+BAO+CMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lnPosterior(theta, z, mu, muError):\n",
    "    lp = lnPrior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnPosteriorWithPriors(theta, z, mu, muError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4658.9477420278481"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1= 500., 0.7, 0.01\n",
    "lnPosterior(theta1, z_SNe_np, mu_SNe_np, muError_SNe_np)\n",
    "\n",
    "# -4658.9477420278481"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAO only. $\\ln({\\rm Posterior}_{\\rm BAO})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-38-d8e49aa24696>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-d8e49aa24696>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    return lp + lnPosteriorWithPriors_BAO(theta)\u001b[0m\n\u001b[0m                                                \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def lnPosterior(theta):\n",
    "    lp = lnPrior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnPosteriorWithPriors_BAO(theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "lnPosterior() takes exactly 4 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-c1e761802c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtheta1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.27\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlnPosterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: lnPosterior() takes exactly 4 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "theta1= 0.27, -0.99, 0.01, 70\n",
    "lnPosterior(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-5.306262772014783\n",
    "-0.42179694422284286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMB only. $\\ln({\\rm Posterior}_{\\rm CMB})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# OK.\n",
    "def lnPosterior(theta):\n",
    "    lp = lnPrior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnLikelihood_CMB(theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theta1= 0.27, -1., 72, 0.0223\n",
    "lnPosterior(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-79.128010582039011\n",
    "-1.864757988671303"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the \"true\" values. This is just to set the starting point for the MCMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining the starting values for the MCMC:\n",
    "Par1_initial = 800\n",
    "Par2_initial = 0.9\n",
    "Par3_initial = 0.0001\n",
    "result = np.array([Par1_initial, Par2_initial, Par3_initial])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The seed for the random numbers (to have reproducible results)\n",
    "np.random.seed(102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNe   or   SNe+CMB+BAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the sampler.\n",
    "\n",
    "# The number of walkers needs to be more than twice the dimension \n",
    "# of your parameter space... unless you're crazy!. \n",
    "# \"walkers\" must be a even number\n",
    "# 4 = The best number that I have found for factor \"1e-4\". When I\n",
    "# put 3 sometimes I get errors.\n",
    "\n",
    "ndim, nwalkers = 3, 20\n",
    "pos = [result + 1e-3*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "\n",
    "# threads=N <-- N = number of parallel process to compute. The first time\n",
    "# it is better to set N=1 to check that everything runs well.\n",
    "# See a note about this below.\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnPosterior, \n",
    "                                args=(z_SNe_np, mu_SNe_np, muError_SNe_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About parallel computing\n",
    "(http://dan.iel.fm/emcee/current/user/advanced/#multiprocessing):\n",
    "\n",
    "\"It is not surprising that running a simple problem like the quickstart example in parallel will run much slower than the equivalent serial code. If your log-probability function takes a significant amount of time (> 1 second or so) to compute then using the parallel sampler actually provides significant speed gains.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running of the MCMC chains:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The running of the MCMC chains.\n",
    "It takes about 10 minutes, but depends on the model, number parameters, number of walkers and number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MCMC... Done.\n"
     ]
    }
   ],
   "source": [
    "# Clear and run the production chain.\n",
    "\n",
    "numberChainSteps = 400\n",
    "sampler.run_mcmc(pos, numberChainSteps, rstate0=np.random.get_state())\n",
    "\n",
    "# Watch out with \"%timeit\"!!: It seems that it makes the mcmc code to run 4 times!\n",
    "# %timeit sampler.run_mcmc(pos, 1000, rstate0=np.random.get_state())\n",
    "\n",
    "print(\"Running MCMC... Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "/Users/arturo/anaconda/lib/python2.7/site-packages/emcee/ensemble.py:335: RuntimeWarning: invalid value encountered in subtract\n",
    "  lnpdiff = (self.dim - 1.) * np.log(zz) + newlnprob - lnprob0\n",
    "/Users/arturo/anaconda/lib/python2.7/site-packages/emcee/ensemble.py:336: RuntimeWarning: invalid value encountered in greater\n",
    "  accept = (lnpdiff > np.log(self._random.rand(len(lnpdiff))))\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5+5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R1 SNe PS1 only, 4 parameters, 40 walkers, 500 steps, interpolated luminosity distance with nbins=31: 4 min 30 sec. \n",
    "\n",
    "_____________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTIONAL. Saving the data for each paramater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving the data of the chains\n",
    "np.savetxt('Chain_Par1.dat', sampler.chain[:, :, 0])\n",
    "np.savetxt('Chain_Par2.dat', sampler.chain[:, :, 1])\n",
    "np.savetxt('Chain_Par3.dat', sampler.chain[:, :, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the evolution of the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, axes = plt.subplots(3, 1, sharex=True, figsize=(8, 9))\n",
    "\n",
    "# w, OmL, OmNu\n",
    "\n",
    "axes[0].plot(sampler.chain[:, :, 0].T, color=\"k\", alpha=0.4)\n",
    "axes[0].yaxis.set_major_locator(MaxNLocator(5))\n",
    "axes[0].axhline(Par1_initial, color=\"#888888\", lw=2)\n",
    "axes[0].set_ylabel(\"$\\omega$\")\n",
    "\n",
    "axes[1].plot(sampler.chain[:, :, 1].T, color=\"k\", alpha=0.4)\n",
    "axes[1].yaxis.set_major_locator(MaxNLocator(5))\n",
    "axes[1].axhline(Par2_initial, color=\"#888888\", lw=2)\n",
    "axes[1].set_ylabel(\"$\\Omega_{\\Lambda}$\")\n",
    "\n",
    "axes[2].plot(sampler.chain[:, :, 2].T, color=\"k\", alpha=0.4)\n",
    "axes[2].yaxis.set_major_locator(MaxNLocator(5))\n",
    "axes[2].axhline(Par3_initial, color=\"#888888\", lw=2)\n",
    "axes[2].set_ylabel(r\"$\\Omega_{\\nu}$\")\n",
    "\n",
    "axes[2].set_xlabel(\"step number\")\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "# SNe\n",
    "NamePlotFileToSave = DirectoryToSaveThePlots+'ChainsEvol_R.png' \n",
    "# SNe+BAO+CMB\n",
    "# NamePlotFileToSave = DirectoryToSaveThePlots+'ChainsEvol_Om_wde_Ho_OmBh2-SNeBAOCMB-R-2.jpeg' \n",
    "# BAO\n",
    "# NamePlotFileToSave = DirectoryToSaveThePlots+'ChainsEvol_Om_wde_Ho_OmBh2-BAO-R-1.jpeg'\n",
    "# CMB\n",
    "# NamePlotFileToSave = DirectoryToSaveThePlots+'ChainsEvol_Om_wde_Ho_OmBh2-CMB-R-1.jpeg'\n",
    "\n",
    "\n",
    "fig.savefig(NamePlotFileToSave, format='png')\n",
    "# fig.savefig(\"R-1-Chains_Om_wde_Ho_OmBh2-PS1-BAO8p-CMBR.jpeg\")\n",
    "plt.show()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Burn-in cut and putting together all the chains (nwalkers) for each parameter together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choosing the Burn-in an creating the sample of data.\n",
    "\n",
    "burnin=500\n",
    "samples = sampler.chain[:, burnin:, :].reshape((-1, ndim))\n",
    "\n",
    "# burninLower = 300\n",
    "# burninUpper = 1000\n",
    "# samples = sampler.chain[:, burninLower:burninUpper, :].reshape((-1, ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the data of the chains already trimmed by burn-in (IMPERATIVE!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving the data of all the chains and parameters\n",
    "\n",
    "NameDataFileToSave = DirectoryToSaveThePlots+'mcmcChains-SNe-R.dat'\n",
    "np.savetxt(NameDataFileToSave, samples)\n",
    "# np.savetxt('R-1-mcmcChains-Burn-200.dat', samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTIONAL: Saving the full data (without trimmed of burn-in) and the $\\chi^2$ value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This table can be useful to plot the data and find the credible regions from the value of chi^2.\n",
    "- The saved file contains the -full- data (i.e., without trimmed from burn-in) of the parameters + the respective chi^2 value.\n",
    "- I have to rewrite this part if I want to save just the trimmed data with their respective chi^2 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chi2values=-2.*sampler.flatlnprobability\n",
    "NoTrimDataParam_Chi2=np.column_stack((sampler.flatchain, chi2values))\n",
    "len(NoTrimDataParam_Chi2),len(NoTrimDataParam_Chi2.T)\n",
    "\n",
    "# Saving the data\n",
    "np.savetxt('R-1-NoTrimData-ParamsAndChi2.dat', NoTrimDataParam_Chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the credible regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All the other options\n",
    "\n",
    "# quantiles=[0.16, 0.50, 0.84]  <-- Quantile lines in marginalized CR\n",
    "# bins= xxx <-- number of bins to divide the data points in the contour plots. \n",
    "#    The smaller the value, the smoother the plot. Default value is about \"bins=50\"\n",
    "# plot_datapoints = False  <-- Do not plot the points of the MCMC (default: True)\n",
    "# plot_ellipse=True\n",
    "# extents=[(1, 5), (1, 8),(0, 10)] # Example for 3 parameters\n",
    "# scale_hist = False\n",
    "\n",
    "fig = triangle.corner(samples, labels=[ \"$w$\", \"$\\Omega_{\\Lambda}$\", \"$\\Omega_{\\mu}$\"],\n",
    "                      truths=[Par1_initial, Par2_initial, Par3_initial],\n",
    "                      # extents=[(1.01, 10.), (40, 80),(60, 120),(0.02,1.0)],\n",
    "                      quantiles=[0.16, 0.50, 0.84], \n",
    "                      bins=41,\n",
    "                      plot_datapoints = True,\n",
    "                      scale_hist=True)\n",
    "\n",
    "# SNe\n",
    "NamePlotFileToSave = DirectoryToSaveThePlots+'CredReg_SNe_R-Q41.png' \n",
    "# SNe+BAO+CMB\n",
    "# NamePlotFileToSave = DirectoryToSaveThePlots+'CredReg_Om_wde_Ho_OmBh2-SNeBAOCMB-R-2-Q41.jpeg'\n",
    "\n",
    "fig.savefig(NamePlotFileToSave, format='png')\n",
    "\n",
    "plt.show() # OK.\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make the triangle plot.\n",
    "\n",
    "fig = triangle.corner(samples, labels=[\"$\\Omega_M$\", \"$w$\", \"$H_0$\", \"$\\Omega_b h^2$\"],\n",
    "                      truths=[Par1_true, Par2_true, Par3_true, Par4_true])\n",
    "\n",
    "# fig = triangle.corner(samples, labels=[\"$\\Omega_M$\", \"$H_0$\"],\n",
    "#                      truths=[Par1_true, Par2_true])\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# fig.savefig(\"R-1-CredReg_Om_wde_Ho_OmBh2-PS1-BAO8p-CMBR.png\")\n",
    "NamePlotFileToSave = DirectoryToSaveThePlots+'R-1-CredReg_Om_wde_Ho_OmBh2-PS1-BAO8p-CMBR.jpeg'  \n",
    "fig.savefig(NamePlotFileToSave, format='jpeg')\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the median and quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Other way to compute the MEAN individually for each parameter.\n",
    "# The result is the same than the case where I compute the mean \n",
    "# of all parameters together with the command above.\n",
    "\n",
    "np.mean(samples.T[0]), np.mean(samples.T[1]), np.mean(samples.T[2]), np.mean(samples.T[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---- Computing the mean, median and quantiles ----\n",
    "\n",
    "# Computing the MEAN\n",
    "print \"The means are:\"\n",
    "print np.mean(samples, axis=0)\n",
    "\n",
    "# Computing the STANDARD DEVIATION\n",
    "print \"The standard deviations are:\"\n",
    "print np.std(samples, axis=0)\n",
    "print \"\"\n",
    "\n",
    "# Computing the percentile.\n",
    "Par1_mcmc, Par2_mcmc, Par3_mcmc, Par4_mcmc = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                             zip(*np.percentile(samples, [16, 50, 84],\n",
    "                                                axis=0)))\n",
    "print(\"\"\"MCMC result:\n",
    "    Par1 = {0[0]} +{0[1]} -{0[2]} (Initial guess: {1})\n",
    "    Par2 = {2[0]} +{2[1]} -{2[2]} (Initial guess: {3})\n",
    "    Par3 = {4[0]} +{4[1]} -{4[2]} (Initial guess: {5})\n",
    "    Par4 = {6[0]} +{6[1]} -{6[2]} (Initial guess: {7})\n",
    "\"\"\".format(Par1_mcmc, Par1_initial, \n",
    "           Par2_mcmc, Par2_initial,\n",
    "           Par3_mcmc, Par3_initial, \n",
    "           Par4_mcmc, Par4_initial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writting results to a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Writting info of this run to a text file. --\n",
    "\n",
    "NameResultsFileToSave = DirectoryToSaveData+\"Results-R_1\"\n",
    "text_file = open(NameResultsFileToSave+\".txt\", \"w\")\n",
    "\n",
    "# Writting the characteristics of this run to a text file.\n",
    "\n",
    "text_file.write('Number random walkers: %s\\n'%(nwalkers) )\n",
    "text_file.write('Number chain steps: %s\\n'%(numberChainSteps) )\n",
    "text_file.write('Burn-in steps: %s\\n'%(burnin) )\n",
    "\n",
    "# --- Writting the results to a file ---\n",
    "\n",
    "text_file.write('\\n') # Make a blank space.\n",
    "\n",
    "text_file.write(\"The means are:\\n\")\n",
    "text_file.write('%s\\n' %(np.mean(samples, axis=0)))\n",
    "\n",
    "text_file.write(\"The standard deviations are:\\n\")\n",
    "text_file.write('%s\\n' %(np.std(samples, axis=0)))\n",
    "\n",
    "text_file.write('\\n') # Make a blank space.\n",
    "    \n",
    "text_file.write(\"\"\"MCMC result:\n",
    "    Par1 = {0[0]} +{0[1]} -{0[2]} (Initial guess: {1})\n",
    "    Par2 = {2[0]} +{2[1]} -{2[2]} (Initial guess: {3})\n",
    "    Par3 = {4[0]} +{4[1]} -{4[2]} (Initial guess: {5})\n",
    "    Par4 = {6[0]} +{6[1]} -{6[2]} (Initial guess: {7})\n",
    "\"\"\".format(Par1_mcmc, Par1_initial, \n",
    "           Par2_mcmc, Par2_initial,\n",
    "           Par3_mcmc, Par3_initial, \n",
    "           Par4_mcmc, Par4_initial))\n",
    "\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDE 1D (like smoothed 1D histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import linspace\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a 1D density: Overlapping the histogram and the KDE PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a 1D density: Overlapping the histogram and the KDE PDF\n",
    "# Parameter 1\n",
    "\n",
    "# Creation of a list for the x-axis, to be used to plot\n",
    "X1_plot = np.linspace(0.03, 0.5, 500)[:, np.newaxis]\n",
    "\n",
    "# histogram data plot\n",
    "plt.hist(samples[:,0:1], bins=80, facecolor='green', alpha=0.2, normed=True)\n",
    "\n",
    "# kde: computation and plotting \n",
    "# The key point is the choise of the \"bandwidth\"\n",
    "kde_1 = KernelDensity(kernel='gaussian', bandwidth=0.03).fit(samples[:,0:1])\n",
    "log_dens_1 = kde_1.score_samples(X1_plot)\n",
    "\n",
    "plt.plot(X1_plot[:, 0], np.exp(log_dens_1), '-', color='red', linewidth=2)\n",
    "\n",
    "plt.xlim(0.02, 0.5)\n",
    "#plt.ylim(0.02, 0.4)\n",
    "#plt.savefig(\"kde_hist1D_Python_Par1_.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a 1D density: Overlapping the histogram and the KDE PDF\n",
    "# Parameter 2\n",
    "\n",
    "# Creation of a list for the x-axis, to be used to plot\n",
    "X2_plot = np.linspace(-2.5, -0.5, 500)[:, np.newaxis]\n",
    "\n",
    "# histogram data plot\n",
    "plt.hist(samples[:,1:2], bins=80, facecolor='green', alpha=0.2, normed=True)\n",
    "\n",
    "# kde: computation and plotting \n",
    "# The key point is the choise of the \"bandwidth\"\n",
    "kde_2 = KernelDensity(kernel='gaussian', bandwidth=0.05).fit(samples[:,1:2])\n",
    "log_dens_2 = kde_2.score_samples(X2_plot)\n",
    "\n",
    "plt.plot(X2_plot[:, 0], np.exp(log_dens_2), '-', color='red', linewidth=2)\n",
    "\n",
    "plt.xlim(-2.5, -0.5)\n",
    "#plt.ylim(0.02, 0.4)\n",
    "# plt.savefig(\"kde_hist1D_Python_Par2_.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking inside of triangle.corner package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(triangle.corner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dis\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inspect.getsourcelines(triangle.corner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dis.dis(triangle.corner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recovering the covariance matrix from Wang et al (2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wang-Etal-2013-DistancePriorsFromPlanck-AndDEConstraints-N.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The normalized covariance matrix\n",
    "NormalCovMatrix=np.array([[1, 0.5250, -0.4235, -0.4475],\n",
    "        [0.5250, 1, -0.6925, -0.8240],\n",
    "        [-0.4235, -0.6925, 1, 0.6109],\n",
    "        [-0.4475, -0.8240, 0.6109, 1]])\n",
    "\n",
    "# The matrix of \"sigmas\"\n",
    "SigmaMatrix=np.array([[0.180*0.18, 0.180* 0.0094, 0.180*0.0003,  0.180* 0.0075],\n",
    "                     [0.0094*0.18, 0.0094*0.0094, 0.0094*0.0003, 0.0094*0.0075],\n",
    "                     [0.0003*0.18 ,0.0003*0.0094 ,0.0003*0.0003, 0.0003*0.0075],\n",
    "                     [0.0075*0.18 ,0.0075*0.0094 ,0.0075*0.0003, 0.0075*0.0075]])\n",
    "\n",
    "# Final covariance matrix\n",
    "CovMatrixCMB= NormalCovMatrix*SigmaMatrix\n",
    "CovMatrixCMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array([[  3.24000000e-02,   8.88300000e-04,  -2.28690000e-05,\n",
    "         -6.04125000e-04],\n",
    "       [  8.88300000e-04,   8.83600000e-05,  -1.95285000e-06,\n",
    "         -5.80920000e-05],\n",
    "       [ -2.28690000e-05,  -1.95285000e-06,   6.00000000e-04,\n",
    "          1.37452500e-06],\n",
    "       [ -6.04125000e-04,  -5.80920000e-05,   1.37452500e-06,\n",
    "          1.50000000e-02]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "0.0003**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From Table 2 of Planck's paper 16-CosmologicalParameters-Published-N.pdf\n",
    "# And comparing with the covariance matrix (2) shown in Betoule et al. 2014.\n",
    "\n",
    "# Uncertainty on Omega_b*h2\n",
    "print np.sqrt(0.79039*10**(-7))\n",
    "\n",
    "# Uncertainty on Omega_c*h2\n",
    "print np.sqrt(66.950*10**(-7))\n",
    "\n",
    "# Uncertainty on 100*theta\n",
    "print np.sqrt(3.9712*10**(-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and plotting together previous MCMC samplings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import triangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Directory to save the data and figures.\n",
    "\n",
    "SuffixRun = '-SNBAOCMB-R-1'\n",
    "\n",
    "DirectoryFiles='/Users/arturo/Dropbox/partage/Research/Ubuntu/RAISIN2015/Compute/SNANA/DanScolnic/Discussion/3_WithCovarianceMatrix/Python_emcee/' \n",
    "\n",
    "DirectoryToSaveThePlots=DirectoryFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SNe+BAO+CMB\n",
    "\n",
    "# Loading all data of each run\n",
    "\n",
    "Run1 = np.genfromtxt(DirectoryFiles+'mcmcChains-Om_wde_Ho-SNBAOCMB-R-1.dat')  \n",
    "Run2 = np.genfromtxt(DirectoryFiles+'mcmcChains-Om_wde_Ho-SNBAOCMB-R-2.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of a single array containing all data of all runs\n",
    "\n",
    "AllRuns = np.vstack([Run1, Run2])\n",
    "\n",
    "len(AllRuns), len(AllRuns.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the best-fit values based on the MINIMUM of the chi^2 function.\n",
    "Par1_initial = 0.27\n",
    "Par2_initial = -1.\n",
    "Par3_initial = 70\n",
    "Par4_initial = 0.0221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All the other options\n",
    "\n",
    "# quantiles=[0.16, 0.50, 0.84]  <-- Quantile lines in marginalized CR\n",
    "# bins= xxx <-- number of bins to divide the data points in the contour plots. \n",
    "#    The smaller the value, the smoother the plot. Default value is about \"bins=50\"\n",
    "# plot_datapoints = False  <-- Do not plot the points of the MCMC (default: True)\n",
    "# plot_ellipse=True\n",
    "# extents=[(1, 5), (1, 8),(0, 10)] # Example for 3 parameters\n",
    "# scale_hist = False\n",
    "\n",
    "fig = triangle.corner(AllRuns[:,0:4], labels=[\"$\\Omega_M$\", \"$w$\", \"$H_0$\", \"$\\Omega_b h^2$\"],\n",
    "                      truths=[Par1_initial, Par2_initial, Par3_initial, Par4_initial],\n",
    "                      # extents=[(1.01, 10.), (40, 80),(60, 120),(0.02,1.0)],\n",
    "                      quantiles=[0.16, 0.50, 0.84], \n",
    "                      bins=40,\n",
    "                      plot_datapoints = True,\n",
    "                      scale_hist=True)\n",
    "\n",
    "\n",
    "# SNe\n",
    "NamePlotFileToSave = DirectoryToSaveThePlots+'CredReg_Om_wde_Ho-Bin31'+SuffixRun \n",
    "# SNe+BAO+CMB\n",
    "# NamePlotFileToSave = DirectoryToSaveThePlots+'CredReg_Om_wde_Ho_OmBh2-SNeBAOCMB-R-2-Q41.jpeg'\n",
    "\n",
    "# fig.savefig(NamePlotFileToSave+'.jpeg', format='jpeg')\n",
    "fig.savefig(NamePlotFileToSave+'-temp.png', format='png')\n",
    "\n",
    "plt.show() # OK.\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---- Computing the mean, median and quantiles ----\n",
    "\n",
    "# Computing the MEAN\n",
    "print \"The means are:\"\n",
    "print np.mean(AllRuns[:,0:4], axis=0)\n",
    "\n",
    "# Computing the STANDARD DEVIATION\n",
    "print \"The standard deviations are:\"\n",
    "print np.std(AllRuns[:,0:4], axis=0)\n",
    "print \"\"\n",
    "\n",
    "# Computing the percentile.\n",
    "Par1_mcmc, Par2_mcmc, Par3_mcmc, Par4_mcmc = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                             zip(*np.percentile(AllRuns[:,0:4], \n",
    "                                                # [16, 50, 84],\n",
    "                                                [15.865, 50., 84.135], # Exact 1-sigma interval.\n",
    "                                                axis=0)))\n",
    "print(\"\"\"MCMC result:\n",
    "    Par1 = {0[0]} +{0[1]} -{0[2]} (Initial guess: {1})\n",
    "    Par2 = {2[0]} +{2[1]} -{2[2]} (Initial guess: {3})\n",
    "    Par3 = {4[0]} +{4[1]} -{4[2]} (Initial guess: {5})\n",
    "    Par4 = {6[0]} +{6[1]} -{6[2]} (Initial guess: {7})\n",
    "\"\"\".format(Par1_mcmc, Par1_initial, \n",
    "           Par2_mcmc, Par2_initial,\n",
    "           Par3_mcmc, Par3_initial, \n",
    "           Par4_mcmc, Par4_initial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# R1 - R2\n",
    "# SNe + BAO + CMB\n",
    "\n",
    "The means are:\n",
    "[  2.59276766e-01  -1.28192296e+00   7.01467853e+01   2.00094895e-02]\n",
    "The standard deviations are:\n",
    "[ 0.03778078  0.24710217  4.517731    0.00616183]\n",
    "\n",
    "MCMC result:\n",
    "    Par1 = 0.256595411477 +0.0397123131521 -0.0343495935974 (Initial guess: 0.25)\n",
    "    Par2 = -1.27999593209 +0.242791689312 -0.241238622656 (Initial guess: -1.28)\n",
    "    Par3 = 69.9205050963 +4.70199973679 -4.27733521173 (Initial guess: 70.0)\n",
    "    Par4 = 0.0194321299004 +0.00667123412042 -0.00549764440515 (Initial guess: 0.0194)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
