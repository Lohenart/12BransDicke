{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\Lambda$CDM: $(\\Omega_{M}, w_0, H_0, \\Omega_{b}h^2)$ Flat Universe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 Points for BAO. R (shift parameter) for CMB. Panstarrs for SNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arturo/anaconda/lib/python2.7/site-packages/IPython/nbformat.py:13: ShimWarning: The `IPython.nbformat` package has been deprecated. You should import from nbformat instead.\n",
      "  \"You should import from nbformat instead.\", ShimWarning)\n",
      "/Users/arturo/anaconda/lib/python2.7/site-packages/nbformat/current.py:19: UserWarning: nbformat.current is deprecated.\n",
      "\n",
      "- use nbformat for read/write/validate public API\n",
      "- use nbformat.vX directly to composing notebooks of a particular version\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import emcee # to MCMC\n",
    "import triangle # to plot MCMC results\n",
    "import numpy as np\n",
    "from scipy.integrate import quad as intquad # To integrate\n",
    "\n",
    "from scipy.interpolate import interp1d # To interpolate the integral in the luminosity distance\n",
    "\n",
    "import matplotlib.pyplot as plt # To plot\n",
    "from matplotlib.ticker import MaxNLocator, NullFormatter  # \n",
    "\n",
    "# ---- To call other iPython codes/notebooks ----\n",
    "import io\n",
    "import nbformat\n",
    "from  IPython.nbformat import current # deprecated\n",
    "\n",
    "# -----------------\n",
    "\n",
    "# import scipy.optimize as op\n",
    "#import math\n",
    "# from math import log10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directory to save the data and figures.\n",
    "\n",
    "DirectoryToSaveThePlots = '/Users/arturo/Dropbox/Research/Articulos/12-BransDick-Norman/12Compute_GitLohen/Plots/' \n",
    "# DirectoryToSaveThePlots = '/Users/arturo/Dropbox/Research/Articulos/0-LCDM-model/emcee/Om-w0-Ho-OmBh2-MAIN/Runs/BAO/8Points/' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General fixed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = 299792.458  # Speed of light\n",
    "\n",
    "HoFix = 70.\n",
    "\n",
    "T_CMB = 2.728 # Temperature of the CMB today, in units of Kelvins\n",
    "OmGammah2 = 2.469*10.**(-5.) # Present amount of photons * h^2. The present total radiation is OmRad = OmGamma + OmNeutrinos.\n",
    "OmRFix =0.000085 # Radiation component today\n",
    "OmBh2Fix = 0.02205 # Planck+WMAP constraint\n",
    "\n",
    "# Range of redshift to interpolate the luminosity distance function\n",
    "zminInterp= 0.\n",
    "zmaxInterp= 1.8\n",
    "nbinszInterp = 31\n",
    "typeInterp = 'quadratic' # kind of interpolation: 'cubic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling functions from another ipython code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining a function that allows me to call and run other ipython codes.\n",
    "\n",
    "def execute_notebook(nbfile):\n",
    "    \n",
    "    with io.open(nbfile) as f:\n",
    "        nb = current.read(f, 'json')\n",
    "        \n",
    "    ip = get_ipython()\n",
    "    \n",
    "    for cell in nb.worksheets[0].cells:\n",
    "        if cell.cell_type != 'code':\n",
    "            continue\n",
    "        ip.run_cell(cell.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the notebook containing all the cosmological functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "execute_notebook(\"BransDickeModelDefinition_v2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code containing the BAO and CMB definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# execute_notebook(\"MAIN-BAO-CMB-Probes.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$d_L = (1+z)^2 D_A$\n",
    "\n",
    "$d_L$ = luminosity distance\n",
    "\n",
    "$D_A$ = Angular diameter distance\n",
    "\n",
    "$D_A = \\frac{c}{H_0} \\frac{{\\rm Sinx} \\left[ H_0 \\sqrt{|\\Omega_K|} \\int^z_0 (dz/H(z)) \\right] }{(1+z)\\sqrt{|\\Omega_K}|}$\n",
    "\n",
    "with Sinx = $\\sin(x)$, $x$, $\\sinh (x)$ for $\\Omega_k <0, \\Omega_k=0, \\Omega_k>0$ respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Actual luminosity distance:\n",
    "# 571.54638336\n",
    "# Interpolated luminosity distance:\n",
    "# 571.546400983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/arturo/Dropbox/Research/Articulos/12-BransDick-Norman/12Compute_GitLohen'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataLocation = '/Users/arturo/Dropbox/Research/Articulos/0-LCDM-model/Data/'\n",
    "\n",
    "z_SNe_np = np.genfromtxt(DataLocation+'Union2_1-SCP-2012.txt', usecols=0)\n",
    "mu_SNe_np = np.genfromtxt(DataLocation+'Union2_1-SCP-2012.txt', usecols=1)\n",
    "muError_SNe_np = np.genfromtxt(DataLocation+'Union2_1-SCP-2012.txt', usecols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ln({\\rm Likelihood}_{\\rm SNe}) = -0.5 \\chi^2_{SNe}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def lnLikelihood_SNe(theta, z, mu, muError):\n",
    "    \"Natural logarithm (ln) of the Likelihood function = -0.5 * Chi2 \"\n",
    "    OmL, OmM, w = theta\n",
    "      \n",
    "    chi2SNeInt = 0.\n",
    "    Ho = HoFix\n",
    "    \n",
    "    for i in range(len(z)):\n",
    "        # Chi2 definition\n",
    "        chi2SNeInt = (chi2SNeInt + ((5.*np.log10(LumDist_Simple(z[i], OmL, OmM, w, Ho)) + 25.-   \n",
    "                         mu[i])/muError[i])**2.)\n",
    "    \n",
    "    lnLikelihoodInt=0.\n",
    "    lnLikelihoodInt=-0.5*chi2SNeInt\n",
    "        \n",
    "    return lnLikelihoodInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3610.0466013024161"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1= 0.7, 0.3, 1000\n",
    "lnLikelihood_SNe(theta1, z_SNe_np, mu_SNe_np, muError_SNe_np)\n",
    "\n",
    "# -3610.0466013024161"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ln({\\rm Likelihood}_{\\rm BAO}) \\propto -0.5\\chi^2_{BAO}$. 8 Points\n",
    "\n",
    "Using the 8 points shown in table VI of my paper about the dimensionless age of the  Universe.\n",
    "\n",
    "Approximation for $r_s$.\n",
    "\n",
    "See also table 6 of 2014-09-02-Rest-Kirshner-Etal-PANSTARRS-CosmologicalConstraintsFromSNeIaDuring1HalfYear-v2-N.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using just 8 points as in Panstarss et al 2014.\n",
    "'''\n",
    "def lnLikelihood_BAO(theta):\n",
    "    \"Chi^2_BAO\"\n",
    "    OmM, wde, Ho, OmBh2 = theta\n",
    "    \n",
    "    # Assumptions about some values:\n",
    "    OmR = OmRFix\n",
    "    \n",
    "    \n",
    "    chi2_BAOInt = (((DVFlat(0.106, OmM, wde, Ho, OmBh2, OmR)-457)/27)**2.+\n",
    "                   ((d_z_Approx(0.20, OmM, wde, Ho, OmBh2, OmR)-0.1905)/0.0061)**2. + \n",
    "                   ((d_z_Approx(0.35, OmM, wde, Ho, OmBh2, OmR)-0.1097)/0.0036)**2. + \n",
    "                   ((AA(0.44, OmM, wde, Ho, OmBh2, OmR)-0.474)/0.034)**2. + \n",
    "                   ((AA(0.60, OmM, wde, Ho, OmBh2, OmR)-0.442)/0.020)**2. + \n",
    "                   ((AA(0.73, OmM, wde, Ho, OmBh2, OmR)-0.424)/0.021)**2. + # I forget to include this point in the computations that I did for the paper with Bob. \n",
    "                   (((1./d_z_Approx(0.35, OmM, wde, Ho, OmBh2, OmR))-8.88)/0.17)**2. + \n",
    "                   (((1./d_z_Approx(0.57, OmM, wde, Ho, OmBh2, OmR))-13.67)/0.22)**2.\n",
    "                   )\n",
    "    return -0.5*chi2_BAOInt\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1=0.27, -1., 72, 0.0221\n",
    "lnLikelihood_BAO(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-8.9677368053993973\n",
    "-8.6859648654294759"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ln({\\rm Likelihood}_{\\rm BAO}) \\propto -0.5\\chi^2_{BAO}$. 1 Point: Percival (2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For 1-point of Percival:\n",
    "- Using $d_z(0.275) = 0.1390 \\pm 0.0037$ and with Gaussian prior on $\\Omega_M h^2 = 0.1326 \\pm 0.0063$\n",
    "\n",
    "- Following Percival et al. (2010). In this paper they assume a fixed value for $\\Omega_b h^2 = 0.0223$ argueing that WMAP has already constrained to tight this value (see pages 2155 and 2156).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def lnLikelihood_BAO(theta):\n",
    "    \"Chi^2_BAO\"\n",
    "    OmM, wde, Ho, OmBh2 = theta  \n",
    "    # Assumptions about some values:\n",
    "    OmR = OmRFix\n",
    "    OmBh2 = 0.0223\n",
    "    \n",
    "    chi2_BAOInt =  (((d_z_Approx(0.275, OmM, wde, Ho, OmBh2, OmR)-0.139)/0.0037)**2.+ \n",
    "                   ((OmM*(Ho/100.)**2. - 0.1326)/0.0063)**2.  # As in Percival (2010)\n",
    "                   ) \n",
    "    \n",
    "    return -0.5*chi2_BAOInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1=0.27, -1., 72, 0.0223\n",
    "lnLikelihood_BAO(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -0.90410732023428819\n",
    "-1.5880002907558326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ln({\\rm Likelihood}_{\\rm BAO}) \\propto -0.5\\chi^2_{BAO}$. 3 Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just 3 points as in Betoule et al 2014, z = 0.106, 0.35, 0.57."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using just 3 points as in Betoule et al 2014, z = 0.106, 0.35, 0.57.\n",
    "'''\n",
    "def lnLikelihood_BAO(theta):\n",
    "    \"Chi^2_BAO\"\n",
    "    OmM, Ho = theta\n",
    "    \n",
    "    # Assumptions about some values:\n",
    "    OmBh2 = OmBaryonh2\n",
    "    wde = -1.\n",
    "    \n",
    "    chi2_BAOInt = (4444.*(d_z_Approx(0.106, OmM, wde, Ho, OmBh2, OmRadiation)-0.336)**2.+\n",
    "                   215156.*(d_z_Approx(0.35, OmM, wde, Ho, OmBh2, OmRadiation)-0.1126)**2.+\n",
    "                   721487.*(d_z_Approx(0.57, OmM, wde, Ho, OmBh2, OmRadiation)-0.07315)**2.)\n",
    "    return -0.5*chi2_BAOInt\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1=0.27, 72\n",
    "lnLikelihood_BAO(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -7.3381747082998565"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\ln({\\rm Posterior_{\\rm total}}) \\propto -0.5  \\chi^2_{total}$. With priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\chi^2_{total}$ = $\\chi^2_{SNe} + \\chi^2_{CMB} + \\chi^2_{BAO} + ({\\rm par}-{\\rm par}_{\\rm obs})^2/\\sigma^2_{\\rm par}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# WATCH OUT!: The priors have to be multiplied by \"-0.5\"!\n",
    "def lnPosteriorWithPriors(theta, z, mu, muError):\n",
    "    \"ln(Posterior) including Gaussian priors\"\n",
    "    OmM, wde, Ho, OmBh2 = theta\n",
    "    \n",
    "    # WATCH OUT!: The priors have to be multiplied by \"-0.5\"!\n",
    "    # At the end of the following expression, include any Gaussian prior\n",
    "    # on any parameters:\n",
    "    \n",
    "    lnPostWithPriorsInt =(lnLikelihood_SNe(theta, z, mu, muError) + \n",
    "                               lnLikelihood_CMB(theta) + \n",
    "                               lnLikelihood_BAO(theta) \n",
    "                               # + (-0.5)*((Ho-73.8)/2.4)**2.  \n",
    "                               )          \n",
    "    return lnPostWithPriorsInt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1= 0.27, -1, 70, 0.022\n",
    "lnPosteriorWithPriors(theta1, z_SNe_np, mu_SNe_np, muError_SNe_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-173.98778712395594\n",
    "-195.82859213726815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-198.92754151237639\n",
    "-198.89658221936472\n",
    "-224.01630580909358\n",
    "-177.24785580909355"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNe Only: $\\ln({\\rm Posterior_{\\rm total}}) \\propto -0.5  \\chi^2_{total}$. With priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WATCH OUT!: The priors have to be multiplied by \"-0.5\"!\n",
    "def lnPosteriorWithPriors(theta, z, mu, muError):\n",
    "    \"ln(Posterior) including Gaussian priors\"\n",
    "    OmL, OmM, w = theta\n",
    "    \n",
    "    '''\n",
    "    if 0.<w<10000 and 0.<OmL<1 and 0.<OmNu<0.02:\n",
    "        lnPostWithPriorsInt = lnLikelihood_SNe(theta, z, mu, muError)\n",
    "        return lnPostWithPriorsInt\n",
    "    return -np.inf\n",
    "    '''\n",
    "     \n",
    "    lnPostWithPriorsInt = lnLikelihood_SNe(theta, z, mu, muError)\n",
    "    return lnPostWithPriorsInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3610.0466013024161"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1= 0.7, 0.3, 1000\n",
    "lnPosteriorWithPriors(theta1, z_SNe_np, mu_SNe_np, muError_SNe_np)\n",
    "# -4658.9477420278481\n",
    "# -3610.0466013024161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3610.0466013024161"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1= 0.7, 0.3, 1000\n",
    "lnPosteriorWithPriors(theta1, z_SNe_np, mu_SNe_np, muError_SNe_np)\n",
    "# -inf\n",
    "# -3610.0466013024161"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAO Only: $\\ln({\\rm Posterior_{\\rm total}}) \\propto -0.5  \\chi^2_{total}$. With priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For 1-point of Percival:\n",
    "- Using $d_z(0.275) = 0.1390 \\pm 0.0037$ and with Gaussian prior on $\\Omega_M h^2 = 0.1326 \\pm 0.0063$\n",
    "\n",
    "- Following Percival et al. (2010). In this paper they assume a fixed value for $\\Omega_b h^2 = 0.0223$ argueing that WMAP has already constrained to tight this value (see pages 2155 and 2156).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def lnPosteriorWithPriors_BAO(theta):\n",
    "    \"ln(Posterior) including Gaussian priors\"\n",
    "    OmM, wde, Ho, OmBh2 = theta\n",
    "    \n",
    "    # WATCH OUT!: The priors have to be multiplied by \"-0.5\"!\n",
    "    # At the end of the following expression, include any Gaussian prior\n",
    "    # on any parameters:\n",
    "    \n",
    "    lnPostWithPriorsInt = lnLikelihood_BAO(theta) \n",
    "  \n",
    "    return lnPostWithPriorsInt\n",
    "    ''' \n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1= 0.27, -1.05, 70, 0.0221\n",
    "lnPosteriorWithPriors_BAO(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-2.5471617321147706\n",
    "-0.17139981360338538 # For 1-point like in Percival assuming a Gaussian prior, with OmBh2 as free parameter\n",
    "-0.14595042592058885 # For 1-point like in Percival assuming a Gaussian prior, with OmBh2=0.0223"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMB Only: $\\ln({\\rm Posterior_{\\rm total}}) \\propto -0.5  \\chi^2_{total}$. With priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lnLikelihood_CMB(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def lnPosteriorWithPriors_CMB(theta):\n",
    "    \"ln(Posterior) including Gaussian priors\"\n",
    "    OmM, wde, Ho, OmBh2 = theta\n",
    "    \n",
    "    # WATCH OUT!: The priors have to be multiplied by \"-0.5\"!\n",
    "    # At the end of the following expression, include any Gaussian prior\n",
    "    # on any parameters:\n",
    "    \n",
    "    lnPostWithPriorsInt =lnLikelihood_CMB(theta)\n",
    "    \n",
    "    return lnPostWithPriorsInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1= 0.27, -1., 72, 0.0221\n",
    "lnPosteriorWithPriors_CMB(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -67.353289088107161 # 3 priors of wang\n",
    "# -63.323159143201366 # 3 CMB priors of Betoule\n",
    "# -1.8633312437581913 # R-CMB only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5+5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limits for each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lnPrior(theta):\n",
    "    \"Natural logarithm (ln) of the prior PDF\"\n",
    "    OmL, OmM, w = theta\n",
    "    \n",
    "    if 0.<OmL<2 and 0<OmM<2 and 0<w<50000 and 9/w**2-6*(OmL + OmM*(2*w+3)/(2*w+4)-1)/w > 0:   \n",
    "        return 0.0\n",
    "    return -np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ln(posterior PDF):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNe only or SNe+BAO+CMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lnPosterior(theta, z, mu, muError):\n",
    "    lp = lnPrior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnPosteriorWithPriors(theta, z, mu, muError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3610.0466013024161"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1= 0.7, 0.3, 1000\n",
    "lnPosterior(theta1, z_SNe_np, mu_SNe_np, muError_SNe_np)\n",
    "\n",
    "# -4658.9477420278481\n",
    "# -3610.0466013024161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1= 1.28189931e+00,   1.55292801e+00,   1.99821133e+03\n",
    "lnPosterior(theta1, z_SNe_np, mu_SNe_np, muError_SNe_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAO only. $\\ln({\\rm Posterior}_{\\rm BAO})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def lnPosterior(theta):\n",
    "    lp = lnPrior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnPosteriorWithPriors_BAO(theta)\n",
    "'''\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1= 0.27, -0.99, 0.01, 70\n",
    "lnPosterior(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-5.306262772014783\n",
    "-0.42179694422284286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the \"true\" values. This is just to set the starting point for the MCMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining the starting values for the MCMC:\n",
    "Par1_initial = 0.999\n",
    "Par2_initial = 0.0001\n",
    "Par3_initial = 8000\n",
    "result = np.array([Par1_initial, Par2_initial, Par3_initial])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The seed for the random numbers (to have reproducible results)\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNe   or   SNe+CMB+BAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the sampler.\n",
    "\n",
    "# The number of walkers needs to be more than twice the dimension \n",
    "# of your parameter space... unless you're crazy!. \n",
    "# \"walkers\" must be a even number\n",
    "# 4 = The best number that I have found for factor \"1e-4\". When I\n",
    "# put 3 sometimes I get errors.\n",
    "\n",
    "ndim, nwalkers = 3, 10\n",
    "pos = [result + 1e-3*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "\n",
    "# threads=N <-- N = number of parallel process to compute. The first time\n",
    "# it is better to set N=1 to check that everything runs well.\n",
    "# See a note about this below.\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnPosterior, \n",
    "                                args=(z_SNe_np, mu_SNe_np, muError_SNe_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About parallel computing\n",
    "(http://dan.iel.fm/emcee/current/user/advanced/#multiprocessing):\n",
    "\n",
    "\"It is not surprising that running a simple problem like the quickstart example in parallel will run much slower than the equivalent serial code. If your log-probability function takes a significant amount of time (> 1 second or so) to compute then using the parallel sampler actually provides significant speed gains.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running of the MCMC chains:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The running of the MCMC chains.\n",
    "It takes about 10 minutes, but depends on the model, number parameters, number of walkers and number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clear and run the production chain.\n",
    "\n",
    "numberChainSteps = 400\n",
    "sampler.run_mcmc(pos, numberChainSteps, rstate0=np.random.get_state())\n",
    "\n",
    "# Watch out with \"%timeit\"!!: It seems that it makes the mcmc code to run 4 times!\n",
    "# %timeit sampler.run_mcmc(pos, 1000, rstate0=np.random.get_state())\n",
    "\n",
    "print(\"Running MCMC... Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"/Users/arturo/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: \n",
    "RuntimeWarning: invalid value encountered in sqrt\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "/Users/arturo/anaconda/lib/python2.7/site-packages/emcee/ensemble.py:335: RuntimeWarning: invalid value encountered in subtract\n",
    "  lnpdiff = (self.dim - 1.) * np.log(zz) + newlnprob - lnprob0\n",
    "/Users/arturo/anaconda/lib/python2.7/site-packages/emcee/ensemble.py:336: RuntimeWarning: invalid value encountered in greater\n",
    "  accept = (lnpdiff > np.log(self._random.rand(len(lnpdiff))))\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5+5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R1 SNe PS1 only, 4 parameters, 40 walkers, 500 steps, interpolated luminosity distance with nbins=31: 4 min 30 sec. \n",
    "\n",
    "_____________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTIONAL. Saving the data for each paramater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving the data of the chains\n",
    "np.savetxt('Chain_Par1.dat', sampler.chain[:, :, 0])\n",
    "np.savetxt('Chain_Par2.dat', sampler.chain[:, :, 1])\n",
    "np.savetxt('Chain_Par3.dat', sampler.chain[:, :, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the evolution of the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, axes = plt.subplots(3, 1, sharex=True, figsize=(8, 9))\n",
    "\n",
    "# w, OmL, OmNu\n",
    "\n",
    "axes[0].plot(sampler.chain[:, :, 0].T, color=\"k\", alpha=0.4)\n",
    "axes[0].yaxis.set_major_locator(MaxNLocator(5))\n",
    "axes[0].axhline(Par1_initial, color=\"#888888\", lw=2)\n",
    "axes[0].set_ylabel(\"$\\Omega_{\\Lambda}$\")\n",
    "\n",
    "\n",
    "axes[1].plot(sampler.chain[:, :, 1].T, color=\"k\", alpha=0.4)\n",
    "axes[1].yaxis.set_major_locator(MaxNLocator(5))\n",
    "axes[1].axhline(Par2_initial, color=\"#888888\", lw=2)\n",
    "axes[1].set_ylabel(\"$\\Omega_{m}$\")\n",
    "\n",
    "axes[2].plot(sampler.chain[:, :, 2].T, color=\"k\", alpha=0.4)\n",
    "axes[2].yaxis.set_major_locator(MaxNLocator(5))\n",
    "axes[2].axhline(Par3_initial, color=\"#888888\", lw=2)\n",
    "axes[2].set_ylabel(\"$\\omega$\")\n",
    "\n",
    "axes[2].set_xlabel(\"step number\")\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "# SNe\n",
    "NamePlotFileToSave = DirectoryToSaveThePlots+'ChainsEvol_R.png' \n",
    "# SNe+BAO+CMB\n",
    "# NamePlotFileToSave = DirectoryToSaveThePlots+'ChainsEvol_Om_wde_Ho_OmBh2-SNeBAOCMB-R-2.jpeg' \n",
    "# BAO\n",
    "# NamePlotFileToSave = DirectoryToSaveThePlots+'ChainsEvol_Om_wde_Ho_OmBh2-BAO-R-1.jpeg'\n",
    "# CMB\n",
    "# NamePlotFileToSave = DirectoryToSaveThePlots+'ChainsEvol_Om_wde_Ho_OmBh2-CMB-R-1.jpeg'\n",
    "\n",
    "\n",
    "fig.savefig(NamePlotFileToSave, format='png')\n",
    "# fig.savefig(\"R-1-Chains_Om_wde_Ho_OmBh2-PS1-BAO8p-CMBR.jpeg\")\n",
    "plt.show()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Burn-in cut and putting together all the chains (nwalkers) for each parameter together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choosing the Burn-in an creating the sample of data.\n",
    "\n",
    "burnin=500\n",
    "samples = sampler.chain[:, burnin:, :].reshape((-1, ndim))\n",
    "\n",
    "# burninLower = 300\n",
    "# burninUpper = 1000\n",
    "# samples = sampler.chain[:, burninLower:burninUpper, :].reshape((-1, ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the data of the chains already trimmed by burn-in (IMPERATIVE!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving the data of all the chains and parameters\n",
    "\n",
    "NameDataFileToSave = DirectoryToSaveThePlots+'mcmcChains-SNe-R.dat'\n",
    "np.savetxt(NameDataFileToSave, samples)\n",
    "# np.savetxt('R-1-mcmcChains-Burn-200.dat', samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTIONAL: Saving the full data (without trimmed of burn-in) and the $\\chi^2$ value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This table can be useful to plot the data and find the credible regions from the value of chi^2.\n",
    "- The saved file contains the -full- data (i.e., without trimmed from burn-in) of the parameters + the respective chi^2 value.\n",
    "- I have to rewrite this part if I want to save just the trimmed data with their respective chi^2 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chi2values=-2.*sampler.flatlnprobability\n",
    "NoTrimDataParam_Chi2=np.column_stack((sampler.flatchain, chi2values))\n",
    "len(NoTrimDataParam_Chi2),len(NoTrimDataParam_Chi2.T)\n",
    "\n",
    "# Saving the data\n",
    "np.savetxt('R-1-NoTrimData-ParamsAndChi2.dat', NoTrimDataParam_Chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the credible regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All the other options\n",
    "\n",
    "# quantiles=[0.16, 0.50, 0.84]  <-- Quantile lines in marginalized CR\n",
    "# bins= xxx <-- number of bins to divide the data points in the contour plots. \n",
    "#    The smaller the value, the smoother the plot. Default value is about \"bins=50\"\n",
    "# plot_datapoints = False  <-- Do not plot the points of the MCMC (default: True)\n",
    "# plot_ellipse=True\n",
    "# extents=[(1, 5), (1, 8),(0, 10)] # Example for 3 parameters\n",
    "# scale_hist = False\n",
    "\n",
    "fig = triangle.corner(samples, labels=[ \"$w$\", \"$\\Omega_{\\Lambda}$\", \"$\\Omega_{\\mu}$\"],\n",
    "                      truths=[Par1_initial, Par2_initial, Par3_initial],\n",
    "                      # extents=[(1.01, 10.), (40, 80),(60, 120),(0.02,1.0)],\n",
    "                      quantiles=[0.16, 0.50, 0.84], \n",
    "                      bins=41,\n",
    "                      plot_datapoints = True,\n",
    "                      scale_hist=True)\n",
    "\n",
    "# SNe\n",
    "NamePlotFileToSave = DirectoryToSaveThePlots+'CredReg_SNe_R-Q41.png' \n",
    "# SNe+BAO+CMB\n",
    "# NamePlotFileToSave = DirectoryToSaveThePlots+'CredReg_Om_wde_Ho_OmBh2-SNeBAOCMB-R-2-Q41.jpeg'\n",
    "\n",
    "fig.savefig(NamePlotFileToSave, format='png')\n",
    "\n",
    "plt.show() # OK.\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make the triangle plot.\n",
    "\n",
    "fig = triangle.corner(samples, labels=[\"$\\Omega_M$\", \"$w$\", \"$H_0$\", \"$\\Omega_b h^2$\"],\n",
    "                      truths=[Par1_true, Par2_true, Par3_true, Par4_true])\n",
    "\n",
    "# fig = triangle.corner(samples, labels=[\"$\\Omega_M$\", \"$H_0$\"],\n",
    "#                      truths=[Par1_true, Par2_true])\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# fig.savefig(\"R-1-CredReg_Om_wde_Ho_OmBh2-PS1-BAO8p-CMBR.png\")\n",
    "NamePlotFileToSave = DirectoryToSaveThePlots+'R-1-CredReg_Om_wde_Ho_OmBh2-PS1-BAO8p-CMBR.jpeg'  \n",
    "fig.savefig(NamePlotFileToSave, format='jpeg')\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the median and quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Other way to compute the MEAN individually for each parameter.\n",
    "# The result is the same than the case where I compute the mean \n",
    "# of all parameters together with the command above.\n",
    "\n",
    "np.mean(samples.T[0]), np.mean(samples.T[1]), np.mean(samples.T[2]), np.mean(samples.T[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---- Computing the mean, median and quantiles ----\n",
    "\n",
    "# Computing the MEAN\n",
    "print \"The means are:\"\n",
    "print np.mean(samples, axis=0)\n",
    "\n",
    "# Computing the STANDARD DEVIATION\n",
    "print \"The standard deviations are:\"\n",
    "print np.std(samples, axis=0)\n",
    "print \"\"\n",
    "\n",
    "# Computing the percentile.\n",
    "Par1_mcmc, Par2_mcmc, Par3_mcmc, Par4_mcmc = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                             zip(*np.percentile(samples, [16, 50, 84],\n",
    "                                                axis=0)))\n",
    "print(\"\"\"MCMC result:\n",
    "    Par1 = {0[0]} +{0[1]} -{0[2]} (Initial guess: {1})\n",
    "    Par2 = {2[0]} +{2[1]} -{2[2]} (Initial guess: {3})\n",
    "    Par3 = {4[0]} +{4[1]} -{4[2]} (Initial guess: {5})\n",
    "    Par4 = {6[0]} +{6[1]} -{6[2]} (Initial guess: {7})\n",
    "\"\"\".format(Par1_mcmc, Par1_initial, \n",
    "           Par2_mcmc, Par2_initial,\n",
    "           Par3_mcmc, Par3_initial, \n",
    "           Par4_mcmc, Par4_initial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writting results to a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Writting info of this run to a text file. --\n",
    "\n",
    "NameResultsFileToSave = DirectoryToSaveData+\"Results-R_1\"\n",
    "text_file = open(NameResultsFileToSave+\".txt\", \"w\")\n",
    "\n",
    "# Writting the characteristics of this run to a text file.\n",
    "\n",
    "text_file.write('Number random walkers: %s\\n'%(nwalkers) )\n",
    "text_file.write('Number chain steps: %s\\n'%(numberChainSteps) )\n",
    "text_file.write('Burn-in steps: %s\\n'%(burnin) )\n",
    "\n",
    "# --- Writting the results to a file ---\n",
    "\n",
    "text_file.write('\\n') # Make a blank space.\n",
    "\n",
    "text_file.write(\"The means are:\\n\")\n",
    "text_file.write('%s\\n' %(np.mean(samples, axis=0)))\n",
    "\n",
    "text_file.write(\"The standard deviations are:\\n\")\n",
    "text_file.write('%s\\n' %(np.std(samples, axis=0)))\n",
    "\n",
    "text_file.write('\\n') # Make a blank space.\n",
    "    \n",
    "text_file.write(\"\"\"MCMC result:\n",
    "    Par1 = {0[0]} +{0[1]} -{0[2]} (Initial guess: {1})\n",
    "    Par2 = {2[0]} +{2[1]} -{2[2]} (Initial guess: {3})\n",
    "    Par3 = {4[0]} +{4[1]} -{4[2]} (Initial guess: {5})\n",
    "    Par4 = {6[0]} +{6[1]} -{6[2]} (Initial guess: {7})\n",
    "\"\"\".format(Par1_mcmc, Par1_initial, \n",
    "           Par2_mcmc, Par2_initial,\n",
    "           Par3_mcmc, Par3_initial, \n",
    "           Par4_mcmc, Par4_initial))\n",
    "\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDE 1D (like smoothed 1D histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import linspace\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a 1D density: Overlapping the histogram and the KDE PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a 1D density: Overlapping the histogram and the KDE PDF\n",
    "# Parameter 1\n",
    "\n",
    "# Creation of a list for the x-axis, to be used to plot\n",
    "X1_plot = np.linspace(0.03, 0.5, 500)[:, np.newaxis]\n",
    "\n",
    "# histogram data plot\n",
    "plt.hist(samples[:,0:1], bins=80, facecolor='green', alpha=0.2, normed=True)\n",
    "\n",
    "# kde: computation and plotting \n",
    "# The key point is the choise of the \"bandwidth\"\n",
    "kde_1 = KernelDensity(kernel='gaussian', bandwidth=0.03).fit(samples[:,0:1])\n",
    "log_dens_1 = kde_1.score_samples(X1_plot)\n",
    "\n",
    "plt.plot(X1_plot[:, 0], np.exp(log_dens_1), '-', color='red', linewidth=2)\n",
    "\n",
    "plt.xlim(0.02, 0.5)\n",
    "#plt.ylim(0.02, 0.4)\n",
    "#plt.savefig(\"kde_hist1D_Python_Par1_.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a 1D density: Overlapping the histogram and the KDE PDF\n",
    "# Parameter 2\n",
    "\n",
    "# Creation of a list for the x-axis, to be used to plot\n",
    "X2_plot = np.linspace(-2.5, -0.5, 500)[:, np.newaxis]\n",
    "\n",
    "# histogram data plot\n",
    "plt.hist(samples[:,1:2], bins=80, facecolor='green', alpha=0.2, normed=True)\n",
    "\n",
    "# kde: computation and plotting \n",
    "# The key point is the choise of the \"bandwidth\"\n",
    "kde_2 = KernelDensity(kernel='gaussian', bandwidth=0.05).fit(samples[:,1:2])\n",
    "log_dens_2 = kde_2.score_samples(X2_plot)\n",
    "\n",
    "plt.plot(X2_plot[:, 0], np.exp(log_dens_2), '-', color='red', linewidth=2)\n",
    "\n",
    "plt.xlim(-2.5, -0.5)\n",
    "#plt.ylim(0.02, 0.4)\n",
    "# plt.savefig(\"kde_hist1D_Python_Par2_.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking inside of triangle.corner package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(triangle.corner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dis\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inspect.getsourcelines(triangle.corner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dis.dis(triangle.corner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recovering the covariance matrix from Wang et al (2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wang-Etal-2013-DistancePriorsFromPlanck-AndDEConstraints-N.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The normalized covariance matrix\n",
    "NormalCovMatrix=np.array([[1, 0.5250, -0.4235, -0.4475],\n",
    "        [0.5250, 1, -0.6925, -0.8240],\n",
    "        [-0.4235, -0.6925, 1, 0.6109],\n",
    "        [-0.4475, -0.8240, 0.6109, 1]])\n",
    "\n",
    "# The matrix of \"sigmas\"\n",
    "SigmaMatrix=np.array([[0.180*0.18, 0.180* 0.0094, 0.180*0.0003,  0.180* 0.0075],\n",
    "                     [0.0094*0.18, 0.0094*0.0094, 0.0094*0.0003, 0.0094*0.0075],\n",
    "                     [0.0003*0.18 ,0.0003*0.0094 ,0.0003*0.0003, 0.0003*0.0075],\n",
    "                     [0.0075*0.18 ,0.0075*0.0094 ,0.0075*0.0003, 0.0075*0.0075]])\n",
    "\n",
    "# Final covariance matrix\n",
    "CovMatrixCMB= NormalCovMatrix*SigmaMatrix\n",
    "CovMatrixCMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array([[  3.24000000e-02,   8.88300000e-04,  -2.28690000e-05,\n",
    "         -6.04125000e-04],\n",
    "       [  8.88300000e-04,   8.83600000e-05,  -1.95285000e-06,\n",
    "         -5.80920000e-05],\n",
    "       [ -2.28690000e-05,  -1.95285000e-06,   6.00000000e-04,\n",
    "          1.37452500e-06],\n",
    "       [ -6.04125000e-04,  -5.80920000e-05,   1.37452500e-06,\n",
    "          1.50000000e-02]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "0.0003**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From Table 2 of Planck's paper 16-CosmologicalParameters-Published-N.pdf\n",
    "# And comparing with the covariance matrix (2) shown in Betoule et al. 2014.\n",
    "\n",
    "# Uncertainty on Omega_b*h2\n",
    "print np.sqrt(0.79039*10**(-7))\n",
    "\n",
    "# Uncertainty on Omega_c*h2\n",
    "print np.sqrt(66.950*10**(-7))\n",
    "\n",
    "# Uncertainty on 100*theta\n",
    "print np.sqrt(3.9712*10**(-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and plotting together previous MCMC samplings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import triangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Directory to save the data and figures.\n",
    "\n",
    "SuffixRun = '-SNBAOCMB-R-1'\n",
    "\n",
    "DirectoryFiles='/Users/arturo/Dropbox/partage/Research/Ubuntu/RAISIN2015/Compute/SNANA/DanScolnic/Discussion/3_WithCovarianceMatrix/Python_emcee/' \n",
    "\n",
    "DirectoryToSaveThePlots=DirectoryFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SNe+BAO+CMB\n",
    "\n",
    "# Loading all data of each run\n",
    "\n",
    "Run1 = np.genfromtxt(DirectoryFiles+'mcmcChains-Om_wde_Ho-SNBAOCMB-R-1.dat')  \n",
    "Run2 = np.genfromtxt(DirectoryFiles+'mcmcChains-Om_wde_Ho-SNBAOCMB-R-2.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of a single array containing all data of all runs\n",
    "\n",
    "AllRuns = np.vstack([Run1, Run2])\n",
    "\n",
    "len(AllRuns), len(AllRuns.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the best-fit values based on the MINIMUM of the chi^2 function.\n",
    "Par1_initial = 0.27\n",
    "Par2_initial = -1.\n",
    "Par3_initial = 70\n",
    "Par4_initial = 0.0221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All the other options\n",
    "\n",
    "# quantiles=[0.16, 0.50, 0.84]  <-- Quantile lines in marginalized CR\n",
    "# bins= xxx <-- number of bins to divide the data points in the contour plots. \n",
    "#    The smaller the value, the smoother the plot. Default value is about \"bins=50\"\n",
    "# plot_datapoints = False  <-- Do not plot the points of the MCMC (default: True)\n",
    "# plot_ellipse=True\n",
    "# extents=[(1, 5), (1, 8),(0, 10)] # Example for 3 parameters\n",
    "# scale_hist = False\n",
    "\n",
    "fig = triangle.corner(AllRuns[:,0:4], labels=[\"$\\Omega_M$\", \"$w$\", \"$H_0$\", \"$\\Omega_b h^2$\"],\n",
    "                      truths=[Par1_initial, Par2_initial, Par3_initial, Par4_initial],\n",
    "                      # extents=[(1.01, 10.), (40, 80),(60, 120),(0.02,1.0)],\n",
    "                      quantiles=[0.16, 0.50, 0.84], \n",
    "                      bins=40,\n",
    "                      plot_datapoints = True,\n",
    "                      scale_hist=True)\n",
    "\n",
    "\n",
    "# SNe\n",
    "NamePlotFileToSave = DirectoryToSaveThePlots+'CredReg_Om_wde_Ho-Bin31'+SuffixRun \n",
    "# SNe+BAO+CMB\n",
    "# NamePlotFileToSave = DirectoryToSaveThePlots+'CredReg_Om_wde_Ho_OmBh2-SNeBAOCMB-R-2-Q41.jpeg'\n",
    "\n",
    "# fig.savefig(NamePlotFileToSave+'.jpeg', format='jpeg')\n",
    "fig.savefig(NamePlotFileToSave+'-temp.png', format='png')\n",
    "\n",
    "plt.show() # OK.\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---- Computing the mean, median and quantiles ----\n",
    "\n",
    "# Computing the MEAN\n",
    "print \"The means are:\"\n",
    "print np.mean(AllRuns[:,0:4], axis=0)\n",
    "\n",
    "# Computing the STANDARD DEVIATION\n",
    "print \"The standard deviations are:\"\n",
    "print np.std(AllRuns[:,0:4], axis=0)\n",
    "print \"\"\n",
    "\n",
    "# Computing the percentile.\n",
    "Par1_mcmc, Par2_mcmc, Par3_mcmc, Par4_mcmc = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                             zip(*np.percentile(AllRuns[:,0:4], \n",
    "                                                # [16, 50, 84],\n",
    "                                                [15.865, 50., 84.135], # Exact 1-sigma interval.\n",
    "                                                axis=0)))\n",
    "print(\"\"\"MCMC result:\n",
    "    Par1 = {0[0]} +{0[1]} -{0[2]} (Initial guess: {1})\n",
    "    Par2 = {2[0]} +{2[1]} -{2[2]} (Initial guess: {3})\n",
    "    Par3 = {4[0]} +{4[1]} -{4[2]} (Initial guess: {5})\n",
    "    Par4 = {6[0]} +{6[1]} -{6[2]} (Initial guess: {7})\n",
    "\"\"\".format(Par1_mcmc, Par1_initial, \n",
    "           Par2_mcmc, Par2_initial,\n",
    "           Par3_mcmc, Par3_initial, \n",
    "           Par4_mcmc, Par4_initial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# R1 - R2\n",
    "# SNe + BAO + CMB\n",
    "\n",
    "The means are:\n",
    "[  2.59276766e-01  -1.28192296e+00   7.01467853e+01   2.00094895e-02]\n",
    "The standard deviations are:\n",
    "[ 0.03778078  0.24710217  4.517731    0.00616183]\n",
    "\n",
    "MCMC result:\n",
    "    Par1 = 0.256595411477 +0.0397123131521 -0.0343495935974 (Initial guess: 0.25)\n",
    "    Par2 = -1.27999593209 +0.242791689312 -0.241238622656 (Initial guess: -1.28)\n",
    "    Par3 = 69.9205050963 +4.70199973679 -4.27733521173 (Initial guess: 70.0)\n",
    "    Par4 = 0.0194321299004 +0.00667123412042 -0.00549764440515 (Initial guess: 0.0194)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
